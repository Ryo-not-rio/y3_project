{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Training and tuning the hyperparameters of the proposed model\n"
      ],
      "metadata": {
        "id": "ZboxmqqMZF-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google drive"
      ],
      "metadata": {
        "id": "rCk5H0ZeaQCt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJuUwtFgkJO1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add drive to python path and change directory. Change '/content/drive/MyDrive/y3_project/models' to 'root_project_folder/models' as necessary. Also install the necessary libraries"
      ],
      "metadata": {
        "id": "3k0gSB2mZM9V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgNeKqLceuG_"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/')\n",
        "%cd '/content/drive/MyDrive/y3_project/models'\n",
        "!pip install tensorflow-text keras-tuner yfinance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning rate grid search"
      ],
      "metadata": {
        "id": "ywdTad6lZjHg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jhI3WZzWhue"
      },
      "outputs": [],
      "source": [
        "## Learning rate grid search\n",
        "\n",
        "import tensorflow as tf\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
        "\n",
        "from model import Model\n",
        "\n",
        "count = 0\n",
        "best_loss = 1.0716042518615723 # (0.001, 0.9, 0.9991)\n",
        "for lr in [0.0099, 0.001, 0.0011]:\n",
        "    for beta_1 in [0.89, 0.9, 0.91]:\n",
        "        for beta_2 in [0.9989, 0.999, 0.9991]:\n",
        "            count += 1\n",
        "            if count <= 17:\n",
        "                continue\n",
        "            \n",
        "            print(f\"\\nTesting {[lr, beta_1, beta_2]}\")\n",
        "\n",
        "            model = Model(seq_length=512, seq_num=1,\n",
        "                            aggregator_size=(2, 256), albert_dense_size=(2, 512),\n",
        "                            gru_shape=(2, 256), gru_dense_size=(2, 512),\n",
        "                            encode_len=512, classifier_size=(1, 512),\n",
        "                            drop_rate=0.01, gru_drop_rate=0.0001,\n",
        "                            regularizer=tf.keras.regularizers.L2(0.0001),\n",
        "                            batch_size=128)\n",
        "\n",
        "            model.train(100, lr=lr, beta_1=beta_1, beta_2=beta_2)\n",
        "            # model.train(100)\n",
        "            result = model.evaluate()\n",
        "            \n",
        "            print(f\"\\n-------------------------------\")\n",
        "            print(f\"Using {lr, beta_1, beta_2}, {result} achieved\")\n",
        "            loss = result[0]\n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "                print(f\"!!!New best loss of {loss} found with {lr, beta_1, beta_2}!!!\")\n",
        "            print(\"--------------------------------\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperband hyperparameter optimization"
      ],
      "metadata": {
        "id": "cphgkdwZZ5dk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAlUW_TRLlSi"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from model import Model\n",
        "\n",
        "def model_builder(hp, return_obj=False):\n",
        "    agg_depth = hp.Int('agg_depth', min_value=1, max_value=4, step=1)\n",
        "    agg_width = hp.Int('agg_width', min_value=64, max_value=384, step=64)\n",
        "    albert_depth = hp.Int('albert_depth', min_value=2, max_value=3, step=1)\n",
        "    albert_width = hp.Int('abert_width', min_value=640, max_value=1536, step=256)\n",
        "    gru_depth = hp.Int('gru_depth', min_value=1, max_value=2, step=1)\n",
        "    gru_width = hp.Int('gru_width', min_value=64, max_value=256, step=32)\n",
        "    gru_dense_depth = hp.Int('gru_dense_depth', min_value=1, max_value=2, step=2)\n",
        "    gru_dense_width = hp.Int('gru_dense_width', min_value=256, max_value=768, step=128)\n",
        "    encode_len = hp.Int('encode_len', min_value=64, max_value=1024, step=64)\n",
        "    classifier_depth = hp.Int('classifier_depth', min_value=1, max_value=3, step=1)\n",
        "    classifier_width = hp.Int('classifier_width', min_value=256, max_value=1024, step=128)\n",
        "    drop_rate = hp.Float('drop_rate', min_value=0.001, max_value=0.5)\n",
        "    gru_drop_rate = hp.Float('gru_drop_rate', min_value=0.001, max_value=0.3)\n",
        "    regularize_rate = hp.Float('regularize', min_value=0.00001, max_value=0.0001)\n",
        "\n",
        "    model_obj = Model(raw_data=True, seq_length=512, seq_num=1,\n",
        "                aggregator_size=(agg_depth, agg_width),\n",
        "                albert_dense_size=(albert_depth, albert_width),\n",
        "                gru_shape=(gru_depth, gru_width), \n",
        "                gru_dense_size=(gru_dense_depth, gru_dense_width),\n",
        "                encode_len=encode_len, classifier_size=(classifier_depth, classifier_width),\n",
        "                drop_rate=drop_rate, gru_drop_rate=gru_drop_rate,\n",
        "                regularizer=tf.keras.regularizers.L2(regularize_rate),\n",
        "                batch_size=128)\n",
        "    model = model_obj.model\n",
        "    model.compile(keras.optimizers.Adam(beta_2=0.9991), loss='categorical_crossentropy', metrics=['accuracy', 'mse'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "ds_model = Model(raw_data=True, seq_length=512, seq_num=1,\n",
        "                aggregator_size=(2, 256), albert_dense_size=(2, 512),\n",
        "                gru_shape=(2, 256), gru_dense_size=(2, 512),\n",
        "                encode_len=512, classifier_size=(1, 512),\n",
        "                drop_rate=0.01, gru_drop_rate=0.0001,\n",
        "                regularizer=tf.keras.regularizers.L2(0.0001),\n",
        "                batch_size=128)\n",
        "\n",
        "train_dataset = ds_model.get_dataset().shuffle(20000, reshuffle_each_iteration=False)\n",
        "validation_dataset = train_dataset.take(512).batch(ds_model.batch_size)\n",
        "train_dataset = train_dataset.skip(512).prefetch(tf.data.AUTOTUNE).shuffle(10000, reshuffle_each_iteration=True).take(5000)\n",
        "train_dataset = train_dataset.batch(ds_model.batch_size)\n",
        "\n",
        "tuner = kt.Hyperband(model_builder, objective='val_accuracy', max_epochs=50, factor=3, hyperband_iterations=2, directory='tuning', project_name=\"raw_data_final\")\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "tuner.search(train_dataset, epochs=50, validation_data=validation_dataset, callbacks=[stop_early])\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "-H1l5VQMalnW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT_bdq_cf1iB"
      },
      "outputs": [],
      "source": [
        "%cd '/content/drive/MyDrive/y3_project/models'\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from model import Model\n",
        "\n",
        "model = Model(raw_data=True, seq_length=512, seq_num=1,\n",
        "                aggregator_size=(3, 128), albert_dense_size=(2, 850),\n",
        "                gru_shape=(1, 96), gru_dense_size=(1, 480),\n",
        "                encode_len=536, classifier_size=(2, 320),\n",
        "                drop_rate=0.186, gru_drop_rate=0.277,\n",
        "                regularizer=tf.keras.regularizers.L2(4e-05),\n",
        "                batch_size=128, checkpoint_file=\"./model_checkpoint\")\n",
        "\n",
        "model.train(100)\n",
        "# tf.keras.utils.plot_model(model.model, expand_nested=True, show_layer_names=False, to_file=\"model.png\")\n",
        "result = model.evaluate()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}